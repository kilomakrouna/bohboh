{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Tomographic Reconstruction from 2D Flat Panel Detector Images\n",
    "\n",
    "This notebook demonstrates the complete workflow for reconstructing 3D volumetric data from a series of 2D projections obtained from a flat panel detector, with support for reading metadata from text files.\n",
    "\n",
    "## Overview\n",
    "1. Data loading and metadata extraction\n",
    "2. Preprocessing and filtering\n",
    "3. Reconstruction algorithm implementation\n",
    "4. 3D visualization\n",
    "5. Export to 3D file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage import io, transform, filters\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from preprocessing import preprocess_projections\n",
    "from reconstruction import filtered_backprojection, art_reconstruction, sirt_reconstruction, fdk_reconstruction\n",
    "from visualization import show_projections, show_sinogram, show_volume_slices, show_volume_3slice, render_surface_plotly\n",
    "from utils import load_projections_with_metadata, create_projection_geometry, save_numpy_as_vtk, save_volume_as_tiff_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Metadata Extraction\n",
    "\n",
    "In this section, we load the 2D projections and associated metadata from text files. The system can automatically find and parse metadata files that accompany TIFF images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "data_path = '../data/raw/'\n",
    "processed_path = '../data/processed/'\n",
    "reconstructions_path = '../data/reconstructions/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [processed_path, reconstructions_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Parameters for loading data\n",
    "file_pattern = '*.tif*'  # Pattern for TIFF files\n",
    "angle_pattern = '_([\\d.]+)deg'  # Pattern to extract angles from filenames (as fallback)\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists(data_path) and len(os.listdir(data_path)) > 0:\n",
    "    # Load projections with metadata\n",
    "    print(\"Loading projections and metadata from files...\")\n",
    "    projections, angles, metadata = load_projections_with_metadata(data_path, file_pattern, angle_pattern)\n",
    "    \n",
    "    print(f\"Loaded {len(projections)} projections with shape {projections[0].shape}\")\n",
    "    print(f\"Angle range: {angles.min():.2f}° to {angles.max():.2f}°\")\n",
    "    \n",
    "    # Print available metadata\n",
    "    print(\"\\nMetadata found:\")\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"  {key}:\")\n",
    "            for subkey, subvalue in value.items():\n",
    "                print(f\"    {subkey}: {subvalue}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Display sample projections\n",
    "    indices = [0, len(projections)//3, 2*len(projections)//3, len(projections)-1]\n",
    "    show_projections(projections, indices)\n",
    "    \n",
    "    # Display a sinogram\n",
    "    show_sinogram(projections)\n",
    "else:\n",
    "    print(\"No data found in the raw data directory. Please add TIFF files before proceeding.\")\n",
    "    print(\"Creating a simulation phantom for demonstration...\")\n",
    "    \n",
    "    # Create a simple phantom (a cube with a sphere inside)\n",
    "    phantom_size = 128\n",
    "    phantom = np.zeros((phantom_size, phantom_size, phantom_size))\n",
    "    \n",
    "    # Add a cube\n",
    "    margin = 20\n",
    "    phantom[margin:-margin, margin:-margin, margin:-margin] = 0.5\n",
    "    \n",
    "    # Add a sphere\n",
    "    x, y, z = np.ogrid[:phantom_size, :phantom_size, :phantom_size]\n",
    "    center = phantom_size // 2\n",
    "    radius = phantom_size // 4\n",
    "    sphere = (x - center)**2 + (y - center)**2 + (z - center)**2 <= radius**2\n",
    "    phantom[sphere] = 1.0\n",
    "    \n",
    "    # Create projection angles\n",
    "    n_angles = 60\n",
    "    angles = np.linspace(0, 360, n_angles, endpoint=False)\n",
    "    \n",
    "    # Create projections\n",
    "    projections = np.zeros((n_angles, phantom_size, phantom_size))\n",
    "    \n",
    "    for i, angle in enumerate(angles):\n",
    "        # Simple parallel beam projection (sum along rotated z-axis)\n",
    "        rotated = ndimage.rotate(phantom, angle, axes=(0, 1), reshape=False, order=1)\n",
    "        projections[i] = np.sum(rotated, axis=0)\n",
    "    \n",
    "    # Normalize projections to [0, 1]\n",
    "    projections = (projections - projections.min()) / (projections.max() - projections.min())\n",
    "    \n",
    "    # Create sample metadata\n",
    "    metadata = {\n",
    "        'source_detector_distance': 1000.0,\n",
    "        'source_object_distance': 500.0,\n",
    "        'exposure_time': 100.0,\n",
    "        'geometry': {\n",
    "            'source_origin_dist': 500.0,\n",
    "            'origin_detector_dist': 500.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save the phantom and projections\n",
    "    np.save(f\"{reconstructions_path}/phantom.npy\", phantom)\n",
    "    np.save(f\"{processed_path}/simulated_projections.npy\", projections)\n",
    "    \n",
    "    # Display sample projections\n",
    "    indices = [0, n_angles//3, 2*n_angles//3, n_angles-1]\n",
    "    show_projections(projections, indices)\n",
    "    \n",
    "    # Display a sinogram\n",
    "    show_sinogram(projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test Metadata Files\n",
    "\n",
    "This cell can be used to create test metadata files if you want to test the metadata reading functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_test_metadata_files(data_path, tiff_files=None):\n",
    "    \"\"\"Create test metadata files for the TIFF files in the given directory.\"\"\"\n",
    "    import glob\n",
    "    import json\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    # Get TIFF files if not provided\n",
    "    if tiff_files is None:\n",
    "        tiff_files = sorted(glob.glob(os.path.join(data_path, '*.tif*')))\n",
    "    \n",
    "    if not tiff_files:\n",
    "        print(\"No TIFF files found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    # Create directory-level metadata file\n",
    "    dir_metadata = {\n",
    "        'source_detector_distance': 1000.0,\n",
    "        'source_object_distance': 500.0,\n",
    "        'pixel_size': 0.2,  # mm\n",
    "        'exposure_time': 100.0,  # ms\n",
    "        'voltage': 120.0,  # kV\n",
    "        'current': 50.0  # mA\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(data_path, 'metadata.txt'), 'w') as f:\n",
    "        for key, value in dir_metadata.items():\n",
    "            f.write(f\"{key} = {value}\\n\")\n",
    "    \n",
    "    print(f\"Created directory metadata file at {os.path.join(data_path, 'metadata.txt')}\")\n",
    "    \n",
    "    # Create individual metadata files for each TIFF\n",
    "    n_files = len(tiff_files)\n",
    "    angles = np.linspace(0, 360, n_files, endpoint=False)\n",
    "    \n",
    "    for i, tiff_file in enumerate(tiff_files):\n",
    "        base_path = os.path.splitext(tiff_file)[0]\n",
    "        \n",
    "        # Create metadata file with angle information\n",
    "        file_metadata = {\n",
    "            'angle': float(angles[i]),\n",
    "            'projection_number': i,\n",
    "            'timestamp': f\"2025-05-04 {i//60:02d}:{i%60:02d}:00\"\n",
    "        }\n",
    "        \n",
    "        # Save as JSON for even indices, text for odd indices (to test both formats)\n",
    "        if i % 2 == 0:\n",
    "            with open(f\"{base_path}.json\", 'w') as f:\n",
    "                json.dump(file_metadata, f, indent=2)\n",
    "        else:\n",
    "            with open(f\"{base_path}.txt\", 'w') as f:\n",
    "                for key, value in file_metadata.items():\n",
    "                    f.write(f\"{key} = {value}\\n\")\n",
    "    \n",
    "    print(f\"Created individual metadata files for {n_files} TIFF files\")\n",
    "\n",
    "# Uncomment the following line to create test metadata files\n",
    "# create_test_metadata_files(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess the projections\n",
    "processed_projections = preprocess_projections(\n",
    "    projections,\n",
    "    angles=angles,\n",
    "    normalize=True,\n",
    "    denoise=True,\n",
    "    remove_rings=True,\n",
    "    correct_rotation=True,\n",
    "    log_transform=True\n",
    ")\n",
    "\n",
    "# Display preprocessed projections\n",
    "show_projections(processed_projections, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometric Setup from Metadata\n",
    "\n",
    "Define the geometry of our imaging setup using the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Use geometry information from metadata if available\n",
    "if 'geometry' in metadata:\n",
    "    source_origin_dist = metadata['geometry']['source_origin_dist']\n",
    "    origin_detector_dist = metadata['geometry']['origin_detector_dist']\n",
    "    print(f\"Using geometry from metadata:\")\n",
    "else:\n",
    "    # Default values if not in metadata\n",
    "    source_origin_dist = 500.0  # mm (distance from source to rotation center)\n",
    "    origin_detector_dist = 500.0  # mm (distance from rotation center to detector)\n",
    "    print(f\"Using default geometry (metadata not available):\")\n",
    "\n",
    "print(f\"  Source to rotation center distance: {source_origin_dist} mm\")\n",
    "print(f\"  Rotation center to detector distance: {origin_detector_dist} mm\")\n",
    "\n",
    "detector_shape = projections.shape[1:3]  # (height, width) of detector\n",
    "\n",
    "# Setup projection geometry\n",
    "geometry = create_projection_geometry(\n",
    "    angles,\n",
    "    detector_shape,\n",
    "    source_origin_dist,\n",
    "    origin_detector_dist\n",
    ")\n",
    "\n",
    "# Define the size of the reconstruction volume\n",
    "volume_size = (detector_shape[0], detector_shape[0], detector_shape[0])  # cubic volume\n",
    "print(f\"Reconstruction volume size: {volume_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconstruction Algorithm Implementation\n",
    "\n",
    "Apply different reconstruction algorithms to create a 3D volume from 2D projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filtered Back Projection (FBP) reconstruction\n",
    "print(\"Starting Filtered Back Projection reconstruction...\")\n",
    "fbp_volume = filtered_backprojection(\n",
    "    processed_projections,\n",
    "    angles,\n",
    "    volume_size\n",
    ")\n",
    "print(\"FBP reconstruction completed.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/fbp_volume.npy\", fbp_volume)\n",
    "save_numpy_as_vtk(fbp_volume, f\"{reconstructions_path}/fbp_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(fbp_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Algebraic Reconstruction Technique (ART)\n",
    "print(\"Starting ART reconstruction...\")\n",
    "art_volume = art_reconstruction(\n",
    "    processed_projections,\n",
    "    angles,\n",
    "    volume_size,\n",
    "    iterations=5  # ART is iterative, so we specify the number of iterations\n",
    ")\n",
    "print(\"ART reconstruction completed.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/art_volume.npy\", art_volume)\n",
    "save_numpy_as_vtk(art_volume, f\"{reconstructions_path}/art_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(art_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# For cone-beam CT, use FDK algorithm with geometry information from metadata\n",
    "print(\"Starting FDK reconstruction...\")\n",
    "fdk_volume = fdk_reconstruction(\n",
    "    processed_projections,\n",
    "    geometry,\n",
    "    volume_size\n",
    ")\n",
    "print(\"FDK reconstruction completed.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/fdk_volume.npy\", fdk_volume)\n",
    "save_numpy_as_vtk(fdk_volume, f\"{reconstructions_path}/fdk_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(fdk_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D Visualization and Export\n",
    "\n",
    "Visualize and export the 3D reconstruction results for use in external 3D software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create interactive 3D visualization with Plotly\n",
    "# Adjust threshold as needed (higher threshold for sparser result)\n",
    "try:\n",
    "    threshold = 0.5 * fbp_volume.max()\n",
    "    fig = render_surface_plotly(fbp_volume, threshold=threshold, opacity=0.7)\n",
    "    fig.write_html(f\"{reconstructions_path}/fbp_isosurface.html\")\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating 3D visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Export as TIFF stack for compatibility with other 3D software\n",
    "save_volume_as_tiff_stack(fbp_volume, f\"{reconstructions_path}/fbp_slices\", \"slice\")\n",
    "print(f\"Saved TIFF stack to {reconstructions_path}/fbp_slices/\")\n",
    "\n",
    "# Also save as VTK file with metadata-based pixel spacing (if available)\n",
    "pixel_size = metadata.get('pixel_size', 1.0) if isinstance(metadata, dict) else 1.0\n",
    "spacing = (pixel_size, pixel_size, pixel_size)\n",
    "save_numpy_as_vtk(fbp_volume, f\"{reconstructions_path}/fbp_volume_scaled.vti\", spacing=spacing)\n",
    "print(f\"Saved scaled VTK file with pixel size = {pixel_size} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing Reconstruction Methods\n",
    "\n",
    "Compare the quality of different reconstruction algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare middle slices of different reconstruction methods\n",
    "methods = ['FBP', 'ART', 'FDK']\n",
    "volumes = [fbp_volume, art_volume, fdk_volume]\n",
    "\n",
    "# Get middle slice\n",
    "mid_z = volume_size[2] // 2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (method, vol) in enumerate(zip(methods, volumes)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(vol[:, :, mid_z], cmap='gray')\n",
    "    plt.title(f\"{method} Reconstruction\")\n",
    "    plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{reconstructions_path}/method_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to load and process 2D projection images with their associated metadata from text files, and perform 3D tomographic reconstruction. The key advantages of this approach are:\n",
    "\n",
    "1. Automatic extraction of geometric parameters from metadata files\n",
    "2. Support for various metadata file formats (JSON, key-value pairs, etc.)\n",
    "3. Fallback to filename-based angle extraction when metadata is unavailable\n",
    "\n",
    "The output includes files that can be opened with common 3D visualization software:\n",
    "- VTK files (.vti) for ParaView, VTK.js, etc.\n",
    "- TIFF stacks for 3D Slicer, ImageJ, etc.\n",
    "- NumPy arrays (.npy) for further processing in Python\n",
    "\n",
    "This approach is particularly useful for working with data from different tomographic imaging systems, where the metadata format may vary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
