{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Tomographic Reconstruction with GPU Acceleration\n",
    "\n",
    "This notebook demonstrates the complete workflow for reconstructing 3D volumetric data from 2D projections with GPU acceleration. The implementation supports:\n",
    "\n",
    "1. **ASTRA Toolbox** - specialized high-performance GPU tomography (fastest)\n",
    "2. **CuPy GPU** - general-purpose GPU acceleration\n",
    "3. **CPU** - fallback implementation\n",
    "\n",
    "## Overview\n",
    "1. Data loading and metadata extraction\n",
    "2. Preprocessing and filtering\n",
    "3. Accelerated reconstruction implementation\n",
    "4. Performance comparison\n",
    "5. 3D visualization and export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage import io, transform, filters\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from preprocessing import preprocess_projections\n",
    "from visualization import show_projections, show_sinogram, show_volume_slices, show_volume_3slice, render_surface_plotly\n",
    "from utils import load_projections_with_metadata, create_projection_geometry, save_numpy_as_vtk, save_volume_as_tiff_stack\n",
    "\n",
    "# Import the accelerated reconstruction module (auto-selects best implementation)\n",
    "from accelerated import (\n",
    "    filtered_backprojection, \n",
    "    art_reconstruction, \n",
    "    sirt_reconstruction, \n",
    "    fdk_reconstruction,\n",
    "    print_gpu_info,\n",
    "    estimate_required_gpu_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Acceleration Information\n",
    "\n",
    "Check what acceleration options are available on this system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Print GPU acceleration information\n",
    "print_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Metadata Extraction\n",
    "\n",
    "In this section, we load the 2D projections and associated metadata from text files. The system can automatically find and parse metadata files that accompany TIFF images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "data_path = '../data/raw/'\n",
    "processed_path = '../data/processed/'\n",
    "reconstructions_path = '../data/reconstructions/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [processed_path, reconstructions_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Parameters for loading data\n",
    "file_pattern = '*.tif*'  # Pattern for TIFF files\n",
    "angle_pattern = '_([\\d.]+)deg'  # Pattern to extract angles from filenames (as fallback)\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists(data_path) and any(f.endswith(('.tif', '.tiff')) for f in os.listdir(data_path)):\n",
    "    # Load projections with metadata\n",
    "    print(\"Loading projections and metadata from files...\")\n",
    "    projections, angles, metadata = load_projections_with_metadata(data_path, file_pattern, angle_pattern)\n",
    "    \n",
    "    print(f\"Loaded {len(projections)} projections with shape {projections[0].shape}\")\n",
    "    print(f\"Angle range: {angles.min():.2f}° to {angles.max():.2f}°\")\n",
    "    \n",
    "    # Print available metadata\n",
    "    print(\"\\nMetadata found:\")\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"  {key}:\")\n",
    "            for subkey, subvalue in value.items():\n",
    "                print(f\"    {subkey}: {subvalue}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Display sample projections\n",
    "    indices = [0, len(projections)//3, 2*len(projections)//3, len(projections)-1]\n",
    "    show_projections(projections, indices)\n",
    "    \n",
    "    # Display a sinogram\n",
    "    show_sinogram(projections)\n",
    "else:\n",
    "    print(\"No data found in the raw data directory. Creating a simulation phantom for demonstration...\")\n",
    "    \n",
    "    # Create a simple phantom (a cube with a sphere inside)\n",
    "    phantom_size = 128\n",
    "    phantom = np.zeros((phantom_size, phantom_size, phantom_size))\n",
    "    \n",
    "    # Add a cube\n",
    "    margin = 20\n",
    "    phantom[margin:-margin, margin:-margin, margin:-margin] = 0.5\n",
    "    \n",
    "    # Add a sphere\n",
    "    x, y, z = np.ogrid[:phantom_size, :phantom_size, :phantom_size]\n",
    "    center = phantom_size // 2\n",
    "    radius = phantom_size // 4\n",
    "    sphere = (x - center)**2 + (y - center)**2 + (z - center)**2 <= radius**2\n",
    "    phantom[sphere] = 1.0\n",
    "    \n",
    "    # Create projection angles\n",
    "    n_angles = 180\n",
    "    angles = np.linspace(0, 180, n_angles, endpoint=False)\n",
    "    \n",
    "    # Create projections\n",
    "    projections = np.zeros((n_angles, phantom_size, phantom_size))\n",
    "    \n",
    "    for i, angle in enumerate(angles):\n",
    "        # Simple parallel beam projection (sum along rotated z-axis)\n",
    "        rotated = ndimage.rotate(phantom, angle, axes=(0, 1), reshape=False, order=1)\n",
    "        projections[i] = np.sum(rotated, axis=0)\n",
    "    \n",
    "    # Normalize projections to [0, 1]\n",
    "    projections = (projections - projections.min()) / (projections.max() - projections.min())\n",
    "    \n",
    "    # Create sample metadata\n",
    "    metadata = {\n",
    "        'source_detector_distance': 1000.0,\n",
    "        'source_object_distance': 500.0,\n",
    "        'exposure_time': 100.0,\n",
    "        'geometry': {\n",
    "            'source_origin_dist': 500.0,\n",
    "            'origin_detector_dist': 500.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save the phantom and projections\n",
    "    np.save(f\"{reconstructions_path}/phantom.npy\", phantom)\n",
    "    np.save(f\"{processed_path}/simulated_projections.npy\", projections)\n",
    "    \n",
    "    # Display sample projections\n",
    "    indices = [0, n_angles//3, 2*n_angles//3, n_angles-1]\n",
    "    show_projections(projections, indices)\n",
    "    \n",
    "    # Display a sinogram\n",
    "    show_sinogram(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess the projections\n",
    "processed_projections = preprocess_projections(\n",
    "    projections,\n",
    "    angles=angles,\n",
    "    normalize=True,\n",
    "    denoise=True,\n",
    "    remove_rings=True,\n",
    "    correct_rotation=True,\n",
    "    log_transform=True\n",
    ")\n",
    "\n",
    "# Display preprocessed projections\n",
    "show_projections(processed_projections, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometric Setup from Metadata\n",
    "\n",
    "Define the geometry of our imaging setup using the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Use geometry information from metadata if available\n",
    "if 'geometry' in metadata:\n",
    "    source_origin_dist = metadata['geometry']['source_origin_dist']\n",
    "    origin_detector_dist = metadata['geometry']['origin_detector_dist']\n",
    "    print(f\"Using geometry from metadata:\")\n",
    "else:\n",
    "    # Default values if not in metadata\n",
    "    source_origin_dist = 500.0  # mm (distance from source to rotation center)\n",
    "    origin_detector_dist = 500.0  # mm (distance from rotation center to detector)\n",
    "    print(f\"Using default geometry (metadata not available):\")\n",
    "\n",
    "print(f\"  Source to rotation center distance: {source_origin_dist} mm\")\n",
    "print(f\"  Rotation center to detector distance: {origin_detector_dist} mm\")\n",
    "\n",
    "detector_shape = projections.shape[1:3]  # (height, width) of detector\n",
    "\n",
    "# Setup projection geometry\n",
    "geometry = create_projection_geometry(\n",
    "    angles,\n",
    "    detector_shape,\n",
    "    source_origin_dist,\n",
    "    origin_detector_dist\n",
    ")\n",
    "\n",
    "# Define the size of the reconstruction volume\n",
    "volume_size = (detector_shape[0], detector_shape[0], detector_shape[0])  # cubic volume\n",
    "print(f\"Reconstruction volume size: {volume_size}\")\n",
    "\n",
    "# Estimate required GPU memory\n",
    "required_gb = estimate_required_gpu_memory(volume_size, projections.shape)\n",
    "print(f\"Estimated GPU memory required: {required_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accelerated Reconstruction \n",
    "\n",
    "Compare different reconstruction algorithms and acceleration methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Filtered Back Projection (FBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run FBP with automatic acceleration (ASTRA > GPU > CPU)\n",
    "print(\"Starting Filtered Back Projection reconstruction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "fbp_volume = filtered_backprojection(\n",
    "    processed_projections,\n",
    "    angles,\n",
    "    volume_size\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"FBP reconstruction completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/fbp_volume.npy\", fbp_volume)\n",
    "save_numpy_as_vtk(fbp_volume, f\"{reconstructions_path}/fbp_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(fbp_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Algebraic Reconstruction Technique (ART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run ART with automatic acceleration\n",
    "print(\"Starting ART reconstruction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "art_volume = art_reconstruction(\n",
    "    processed_projections,\n",
    "    angles,\n",
    "    volume_size,\n",
    "    iterations=5  # ART is iterative, so we specify the number of iterations\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"ART reconstruction completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/art_volume.npy\", art_volume)\n",
    "save_numpy_as_vtk(art_volume, f\"{reconstructions_path}/art_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(art_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SIRT Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run SIRT with automatic acceleration\n",
    "print(\"Starting SIRT reconstruction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "sirt_volume = sirt_reconstruction(\n",
    "    processed_projections,\n",
    "    angles,\n",
    "    volume_size,\n",
    "    iterations=20\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"SIRT reconstruction completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/sirt_volume.npy\", sirt_volume)\n",
    "save_numpy_as_vtk(sirt_volume, f\"{reconstructions_path}/sirt_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(sirt_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 FDK Reconstruction (Cone Beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run FDK with automatic acceleration\n",
    "print(\"Starting FDK reconstruction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "fdk_volume = fdk_reconstruction(\n",
    "    processed_projections,\n",
    "    geometry,\n",
    "    volume_size\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"FDK reconstruction completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Save the reconstructed volume\n",
    "np.save(f\"{reconstructions_path}/fdk_volume.npy\", fdk_volume)\n",
    "save_numpy_as_vtk(fdk_volume, f\"{reconstructions_path}/fdk_volume.vti\")\n",
    "\n",
    "# Display orthogonal slices of the reconstructed volume\n",
    "show_volume_3slice(fdk_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Acceleration Method Comparison\n",
    "\n",
    "Compare the performance of different acceleration methods for FBP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare the performance of different acceleration methods for FBP\n",
    "methods = []\n",
    "times = []\n",
    "\n",
    "# Only run if volume is not too large to avoid memory issues\n",
    "if np.prod(volume_size) <= 256**3:  # Skip for very large volumes \n",
    "    # CPU implementation\n",
    "    print(\"\\nRunning CPU implementation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cpu_volume = filtered_backprojection(\n",
    "        processed_projections,\n",
    "        angles,\n",
    "        volume_size,\n",
    "        use_gpu=False,\n",
    "        use_astra=False\n",
    "    )\n",
    "    \n",
    "    cpu_time = time.time() - start_time\n",
    "    print(f\"CPU time: {cpu_time:.2f} seconds\")\n",
    "    methods.append(\"CPU\")\n",
    "    times.append(cpu_time)\n",
    "    \n",
    "    # CuPy GPU implementation\n",
    "    try:\n",
    "        print(\"\\nRunning CuPy GPU implementation...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        gpu_volume = filtered_backprojection(\n",
    "            processed_projections,\n",
    "            angles,\n",
    "            volume_size,\n",
    "            use_gpu=True,\n",
    "            use_astra=False\n",
    "        )\n",
    "        \n",
    "        gpu_time = time.time() - start_time\n",
    "        print(f\"CuPy GPU time: {gpu_time:.2f} seconds\")\n",
    "        print(f\"Speedup: {cpu_time / gpu_time:.1f}x\")\n",
    "        methods.append(\"CuPy GPU\")\n",
    "        times.append(gpu_time)\n",
    "    except Exception as e:\n",
    "        print(f\"CuPy GPU implementation failed: {e}\")\n",
    "    \n",
    "    # ASTRA implementation\n",
    "    try:\n",
    "        print(\"\\nRunning ASTRA Toolbox implementation...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        astra_volume = filtered_backprojection(\n",
    "            processed_projections,\n",
    "            angles,\n",
    "            volume_size,\n",
    "            use_gpu=True,\n",
    "            use_astra=True\n",
    "        )\n",
    "        \n",
    "        astra_time = time.time() - start_time\n",
    "        print(f\"ASTRA time: {astra_time:.2f} seconds\")\n",
    "        print(f\"Speedup: {cpu_time / astra_time:.1f}x\")\n",
    "        methods.append(\"ASTRA\")\n",
    "        times.append(astra_time)\n",
    "    except Exception as e:\n",
    "        print(f\"ASTRA implementation failed: {e}\")\n",
    "    \n",
    "    # Plot performance comparison\n",
    "    if len(methods) > 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(methods, times)\n",
    "        plt.title(\"Reconstruction Performance Comparison\")\n",
    "        plt.ylabel(\"Time (seconds)\")\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add speedup annotations\n",
    "        for i, time_val in enumerate(times):\n",
    "            if i > 0:  # Skip the first bar (CPU)\n",
    "                speedup = times[0] / time_val\n",
    "                plt.text(i, time_val + 0.05 * max(times), \n",
    "                       f\"{speedup:.1f}x faster\", \n",
    "                       ha='center', va='bottom')\n",
    "            plt.text(i, time_val / 2, f\"{time_val:.2f}s\", ha='center', va='center', color='white', fontweight='bold')\n",
    "        \n",
    "        plt.savefig(f\"{reconstructions_path}/acceleration_comparison.png\", dpi=300)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Volume is too large for performance comparison. Skipping benchmark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 3D Visualization and Export\n",
    "\n",
    "Visualize the 3D reconstruction results and export to common 3D file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create interactive 3D visualization with Plotly\n",
    "# Adjust threshold as needed (higher threshold for sparser result)\n",
    "try:\n",
    "    threshold = 0.5 * fbp_volume.max()\n",
    "    fig = render_surface_plotly(fbp_volume, threshold=threshold, opacity=0.7)\n",
    "    fig.write_html(f\"{reconstructions_path}/fbp_isosurface.html\")\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating 3D visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Export as TIFF stack for compatibility with other 3D software\n",
    "save_volume_as_tiff_stack(fbp_volume, f\"{reconstructions_path}/fbp_slices\", \"slice\")\n",
    "print(f\"Saved TIFF stack to {reconstructions_path}/fbp_slices/\")\n",
    "\n",
    "# Also save as VTK file with metadata-based pixel spacing (if available)\n",
    "pixel_size = metadata.get('pixel_size', 1.0) if isinstance(metadata, dict) else 1.0\n",
    "spacing = (pixel_size, pixel_size, pixel_size)\n",
    "save_numpy_as_vtk(fbp_volume, f\"{reconstructions_path}/fbp_volume_scaled.vti\", spacing=spacing)\n",
    "print(f\"Saved scaled VTK file with pixel size = {pixel_size} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Comparison\n",
    "\n",
    "Compare the quality of different reconstruction algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare middle slices of different reconstruction methods\n",
    "methods = ['FBP', 'ART', 'SIRT', 'FDK']\n",
    "volumes = [fbp_volume, art_volume, sirt_volume, fdk_volume]\n",
    "\n",
    "# Get middle slice\n",
    "mid_z = volume_size[2] // 2\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i, (method, vol) in enumerate(zip(methods, volumes)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(vol[:, :, mid_z], cmap='gray')\n",
    "    plt.title(f\"{method} Reconstruction\")\n",
    "    plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{reconstructions_path}/method_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the benefits of GPU acceleration for tomographic reconstruction:\n",
    "\n",
    "1. **ASTRA Toolbox** provides the fastest performance, as it's specifically optimized for tomography\n",
    "2. **CuPy GPU** implementation offers good general-purpose acceleration\n",
    "3. **CPU** implementation serves as a reliable fallback\n",
    "\n",
    "We've also shown how to read metadata from accompanying text files in various formats, and how to export the 3D reconstruction results in formats compatible with common 3D visualization software."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
